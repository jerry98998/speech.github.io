# Paper And Demo

## 1.联合时频域扩张卷积的耳语音向正常音转换方法及其装置

Jian Zhou, Yan Huang · Published 2020 · Patent

Abstract：本发明公开了一种联合时频域扩张卷积的耳语音向正常音转换方法及其装置.该方法包括:提取耳语音的谱包络,正常音的谱包络,非周期成分以及基频;将谱包络对齐,并转化为第一梅尔倒谱系数特征,第二梅尔倒谱系数特征;训练出谱包络转换模型,非周期转换模型以及基频转换模型;提取耳语的谱包络,并转化为第三梅尔倒谱系数特征;将第三梅尔倒谱系数特征进行转换,获得预测梅尔倒谱系数特征,预测非周期成分以及预测基频;将预测梅尔倒谱系数特征还原成预测谱包络;将预测谱包络,预测非周期成分以及预测基频合成为预测语音.本发明有效捕获语音时频域局部特征,可以显著降低模型参数量,提高语音转换速率,提升语音质量,语音可懂度以及连续性.

You can get paper [here](https://xueshu.baidu.com/usercenter/paper/show?paperid=1g6m06j0du670020j34j0p70q5456038&site=xueshu_se)

You can find a demo [here](https://meigm.github.io/DCNNdemo/dcnn.html)

## 2.Audio samples for "SETransformer: Transformer Speech enhancement"

WeiWei Yu, Jian Zhou, HuaBin Wang, Liang Tao, Hon Keung Kwan · Published 2021 · Cognitive Computation

Abstract：Speech enhancement is a fundamental way to improve speech perception quality in adverse environment where the received speech is seriously corrupted by noise. In this paper, we propose a cognitive computing based speech enhancement model termed SETransformer which can improve the speech quality in unkown noisy environments. The proposed SETransformer takes advantages of LSTM and multi-head attention mechanism, both of which are inspired by the auditory perception principle of human beings. Specifically, the SETransformer pocesses the ability of characterizing the local structure implicated in the speech spectrum and has more lower computation complexity due to its distinctive parallelization perfermance. Experimental results show that, compared with the standard Transformer and the LSTM model, the proposed SETransformer model can consistently achieve better denoising performance in terms of speech quality (PESQ) and speech intelligibility (STOI) under unseen noise conditions.

You can get paper [here](https://www.researchgate.net/publication/349006945_SETransformer_Speech_Enhancement_Transformer)

You can find a demo [here](https://withoutdoubt.github.io/YWW.github.io/index.html)

## 3.Parallel CycleGAN with Dual Adversarial Loss for Bone-Conducted Speech Enhancement

Qing Pan, Teng Gao, Jian Zhou, Huabin Wang, Liang Tao, and Hon Keung Kwan · Published 2021 · 

Abstract：Compared with air-conducted speech, bone-conducted speech has the unique advantage of shielding background noise. Enhancement of bone-conducted speech helps to improve its quality and intelligibility. In this paper, a novel Parallel CycleGAN with dual adversarial loss is proposed for bone-conducted speech enhancement. The proposed method uses an adversarial loss and a cyclic consistent loss simultaneously to learn forward and cyclic mapping, in which the adversarial loss is divided into the classification adversarial loss and the defect adversarial loss to consolidate the forward mapping. Compared with conventional baseline methods, it can learn feature mapping between bone-conducted speech and target speech without additional air-conducted speech assistance. Moreover, the proposed method also avoids the over-smooth problem which is occurred commonly in conventional statistical based models. Experimental results show that the proposed method outperforms baseline methods such as CycleGAN, GMM, and BLSTM.

Paper is not available for now

You can find a demo [here](https://qpan77.github.io/Dadv_Cycle/demo.html)

## 2.Audio samples for "SETransformer: Transformer Speech enhancement"

WeiWei Yu, Jian Zhou, HuaBin Wang, Liang Tao, Hon Keung Kwan · Published 2021 · Cognitive Computation

Abstract：Speech enhancement is a fundamental way to improve speech perception quality in adverse environment where the received speech is seriously corrupted by noise. In this paper, we propose a cognitive computing based speech enhancement model termed SETransformer which can improve the speech quality in unkown noisy environments. The proposed SETransformer takes advantages of LSTM and multi-head attention mechanism, both of which are inspired by the auditory perception principle of human beings. Specifically, the SETransformer pocesses the ability of characterizing the local structure implicated in the speech spectrum and has more lower computation complexity due to its distinctive parallelization perfermance. Experimental results show that, compared with the standard Transformer and the LSTM model, the proposed SETransformer model can consistently achieve better denoising performance in terms of speech quality (PESQ) and speech intelligibility (STOI) under unseen noise conditions.

You can get paper [here](https://www.researchgate.net/publication/349006945_SETransformer_Speech_Enhancement_Transformer)

You can find a demo [here](https://withoutdoubt.github.io/YWW.github.io/index.html)

